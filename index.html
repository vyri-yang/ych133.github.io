<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Scrollspy</title>
    <link rel="stylesheet" href="dist/css/scrollspy.min.css"/>

    <!--link rel="stylesheet" href="dist/css/demo.css"-->
    <!--link rel="stylesheet" href="dist/css/mn-accordion.css"-->

    

    
  </head>
  <body>
    <nav class="scrollspy-nav">
      <a class="scrollspy-link" data-target="Home">Home</a>
      <!--a class="scrollspy-link" data-target="Projects">Projects</a-->
      <a class="scrollspy-link" data-target="Publications">Publications</a>
      <a class="scrollspy-link" data-target="Videos">Videos</a>
      <a class="scrollspy-link" data-target="News & features" style="margin-right: 40px;">News & features</a>
      <span class="scrollspy-indicator"></span>
    </nav>
    <section class="scrollspy-section" id="Home">
      <div class="main">
        <div class="photo">
            <img src="img/21641170378_.pic_.jpg" alt="" class="photo_img">
        </div>
        <div class="about">
            <div class="intro_text">Principal Researcher</div>
            <div class="name">Yu Cheng</div>
            <div class="cont">I am a Principal Researcher at Microsoft Research. Before joining Microsoft, I was a Research Staff Member at IBM Research & MIT-IBM Watson AI Lab. I got a Ph.D. degree from Northwestern University in 2015 and a bachelor’s degree from Tsinghua University in 2010. My research covers deep learning in general, with specific interests in model compression and efficiency, deep generative models, and adversarial robustness. Currently, I focus on solving challenging problems and productionizing these techniques for Microsoft (e.g., Copilot, DALL-E-2, ChatGPT, GPT-4). I am serving (or, have served) as an area chair for CVPR, NeurIPS, AAAI, IJCAI, ACMMM, WACV, and ECCV.</div>
            <div class="download_btn">Download CV</div>
        </div>
    </div>
    </section>
    <div class="gray">
      <div class="section_1">
          <div class="title">Latest News
              <div class="line"></div>
          </div>
          <div class="cont margin_left">
              ● Serving as Area Chair for NeurIPS 2023, ACMMM 2023 (Mar. 2023)<br>
              ● I organized the <a href="https://rtml-iclr2023.github.io/cfp.html" 
              style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                Trustworthy and Reliable Large-Scale Machine Learning Models workshop</a> 
              at ICLR 2023. Please consider submitting your work to the workshop (Feb. 2023)<br>
              ● Invited talk at <a href="https://mp.weixin.qq.com/s/OOIV_Byo6_3g8qLVtFEPpA" 
              style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                Fudan University</a> (Dec. 2022)<br>
              ● Invited talk at <a href="https://sites.google.com/rice.edu/iccad-halo-2022/schedule?authuser=0" 
              style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                Hardware and Algorithms for Learning On-a-chip (HALO) workshop</a> at ICCAD 2022 (Nov. 2022)<br>
              ● Serving as Area Chair for CVPR 2023, WACV 2023, and AAAI 2023 (Sep. 2022)<br>
              ● Invited panel talk at <a href="https://nips.cc/virtual/2022/workshop/49974" 
              style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                Efficient Natural Language and Speech Processing workshop</a> at NeurIPS 2022 (Dec. 2022)<br>
              ● Invited talk at <a href="https://eccv2022.ecva.net/program/workshop-schedule/" 
              style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                Learning with Limited and Imperfect Data workshop</a> at ECCV 2022 (Oct. 2022)<br>
              ● Serving as Area Chair for ACMMM 2022, NeurIPS 2022 (Mar. 2022)<br>
              ● Invited talks at <a href="https://www.microsoft.com/en-us/research/video/refai-seminar-06-08-21-transformer-efficiency-from-model-compression-to-training-acceleration/" 
              style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                Rutergus University</a>, Bytedance AI Lab, and Microsoft Research Summit about model/data efficient CV/NLP/Multimodal models (Jan. 2022)<br>
          </div>
  
  
      </div>
  </div>
    <!--section class="scrollspy-section" id="Projects">
      <div class="section_2" >
        <div class="title">Projects
            <div class="line"></div>
        </div>
        <div class="grids">
          <div class="list">
            <div class="sub-title"><a  href="footprint.html" style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark">Reducing AI's Carbon <br>Footprint ></a></div>
            <div class="cont overflow">
              This project develops techniques that enable AI to use computing infrastructure more efficiently. 
              The goals are to maintain predictive accuracy while reducing carbon emissions, whether embodied in 
              manufactured hardware, or produced from electricity usage when green energy is not available.
            </div>
          </div>
          <div class="list">
            <div class="sub-title"><a  href="Distillation.html" style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark">Knowledge Distillation ></a></div>
            <div class="cont overflow">
              Modern machine learning applications have enjoyed a great boost utilizing deep and large neural network models, 
              allowing them to achieve state-of-the-art results on a wide range of tasks such as question-answering, 
              conversational AI, search and recommendation. A significant challenge facing practitioners is how to deploy 
              these huge models in practice. Recent pre-trained language models like Turing-NLG and GPT-3 ...
            </div>
          </div>
            
        </div>

    </div>
    </section-->

    <section class="scrollspy-section" id="Publications">
      <div class="section_2" >
        <div class="title">Publications
            <div class="line"></div>
        </div>
        <div class="mn-acc-app">
          <div class="mn-accordion" id="accordion-2">
      
              <!--Accordion item-->
              <div class="accordion-item">
                  <div class="accordion-heading">
                      <h3>2023</h3>
                      <div class="icon">
                          <i class="arrow right"></i>
                      </div>
                  </div>
                  <div class="accordion-content">
                      <!--publication section-->
                      <div style="padding-bottom:0px">
                        <div class="sub-title_ss">
                          <a href="https://www.microsoft.com/en-us/research/publication/adaptive-budget-allocation-for-parameter-efficient-fine-tuning/" 
                        style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                        Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning ></a>
                        </div>
                        <div class="sec_sub_title_s">Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen, Tuo Zhao</div>
                        <div class="sec_sub_title_s"><a style="font-weight: bold;">11th International Conference on Learning Representations (ICLR 2023)</a> | May 2023</div>
                        <div class="sec_sub_title_a">
                          <a href="https://openreview.net/pdf?id=lq62uWRJjiY" 
                        style=" color:#3f44b6;" rel="alternate bookmark" target="_blank">
                        View Publication</a>
                        </div>
                      </div>
                      <!--publication section-->

                      <!--publication section-->
                      <div style="padding-bottom:0px">
                        <div class="sub-title_ss">
                          <a href="https://www.microsoft.com/en-us/research/publication/what-do-compressed-large-language-models-forget-robustness-challenges-in-model-compression/" 
                        style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                        What do Compressed Large Language Models Forget? Robustness Challenges in Model Compression ></a>
                        </div>
                        <div class="sec_sub_title_s">Mengnan Du, Subhabrata (Subho) Mukherjee, Yu Cheng, Milad Shokouhi, Xia Hu, Ahmed H. Awadallah</div>
                        <div class="sec_sub_title_s"><a style="font-weight: bold;">17th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2023)</a> | April 2023</div>
                        <div class="sec_sub_title_a">
                          <a href="https://arxiv.org/pdf/2110.08419.pdf" 
                        style=" color:#3f44b6;" rel="alternate bookmark" target="_blank">
                        View Publication</a>
                        </div>
                      </div>
                      <!--publication section-->

                      <!--publication section-->
                      <div style="padding-bottom:0px">
                        <div class="sub-title_ss">
                          <a href="https://www.microsoft.com/en-us/research/publication/frido-feature-pyramid-diffusion-for-complex-scene-image-synthesis/" 
                        style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                        Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis ></a>
                        </div>
                        <div class="sec_sub_title_s">Wan-Cyuan Fan, Yen-Chun Chen, Dongdong Chen, Yu Cheng, Lu Yuan, Yu-Chiang Frank Wang</div>
                        <div class="sec_sub_title_s"><a style="font-weight: bold;">In Thirty-Seven AAAI Conference on Artificial Intelligence (AAAI 2023)</a> | January 2023</div>
                        <div class="sec_sub_title_a">
                          <a href="https://arxiv.org/abs/2208.13753" 
                        style=" color:#3f44b6;" rel="alternate bookmark" target="_blank">
                        View Publication</a>
                        </div>
                      </div>
                      <!--publication section-->


                      <!--last publication section-->
                      <div style="padding-bottom:30px">
                        <div class="sub-title_ss">
                          <a href="https://www.microsoft.com/en-us/research/publication/hypotheses-tree-building-for-one-shot-temporal-sentence-localization/" 
                        style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                        Hypotheses Tree Building for One-Shot Temporal Sentence Localization ></a>
                        </div>
                        <div class="sec_sub_title_s">Daizong Liu, Xiang Fang, Pan Zhou, Xing Di, Weining Lu, Yu Cheng</div>
                        <div class="sec_sub_title_s"><a style="font-weight: bold;">In Thirty-Seven AAAI Conference on Artificial Intelligence (AAAI 2023)</a> | January 2023</div>
                        <div class="sec_sub_title_a">
                          <a href="https://www.microsoft.com/en-us/research/people/yucheng1/publications/" 
                        style=" color:#3f44b6;" rel="alternate bookmark" target="_blank">
                        View Publication</a>
                        </div>
                      </div>
                      <!--publication section-->

                  </div>
              </div>
              <!--Accordion item-->
      
              <!--Accordion item-->
              <div class="accordion-item">
                  <div class="accordion-heading">
                      <h3>2022</h3>
                      <div class="icon">
                          <i class="arrow right"></i>
                      </div>
                  </div>
                  <div class="accordion-content">

                    <!--添加內容，最後的section樣式有區別，同時有download和view的section，copy ‘publication section with download’ 的樣式-->
                     
                  </div>
              </div>
              <!--Accordion item-->
      
              <!--Accordion item-->
              <div class="accordion-item">
                  <div class="accordion-heading">
                      <h3>2021</h3>
                      <div class="icon">
                          <i class="arrow right"></i>
                      </div>
                  </div>
                  <div class="accordion-content">

                    <!--添加內容，最後的section樣式有區別，同時有download和view的section，copy ‘publication section with download’ 的樣式-->
                      
                  </div>
              </div>
              <!--Accordion item-->

              <!--Accordion item-->
              <div class="accordion-item">
                <div class="accordion-heading">
                    <h3>2020</h3>
                    <div class="icon">
                        <i class="arrow right"></i>
                    </div>
                </div>
                <div class="accordion-content">

                  <!--添加內容，最後的section樣式有區別，同時有download和view的section，copy ‘publication section with download’ 的樣式-->
                     
                </div>
            </div>
            <!--Accordion item-->

            <!--Accordion item-->
            <div class="accordion-item">
              <div class="accordion-heading">
                  <h3>2019</h3>
                  <div class="icon">
                      <i class="arrow right"></i>
                  </div>
              </div>
              <div class="accordion-content">
                <!--publication section with download-->
                <div style="padding-bottom:0px">
                  <div class="sub-title_ss">
                    <a href="https://www.microsoft.com/en-us/research/publication/discourse-aware-neural-extractive-model-for-text-summarization/" 
                  style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                  Discourse-Aware Neural Extractive Model for Text Summarization. ></a>
                  </div>
                  <div class="sec_sub_title_s">Jiacheng Xu, Zhe Gan, Yu Cheng, Jingjing Liu</div>
                  <div class="sec_sub_title_s"><a style="font-weight: bold;">58th Annual Meeting of Association for Computational Linguistics (ACL 2020)</a> | October 2019</div>
                  <div class="sec_sub_title_a">
                    <a href="https://arxiv.org/pdf/1910.14142v1.pdf" 
                  style=" color:#3f44b6;" rel="alternate bookmark" target="_blank">
                  Download PDF</a>
                    | <a href="https://arxiv.org/abs/1910.14142v1" 
                  style=" color:#3f44b6;" rel="alternate bookmark" target="_blank">
                  View Publication</a>
                  </div>
                </div>
                <!--publication section-->

                <!--last publication section-->
                <div style="padding-bottom:30px">
                  <div class="sub-title_ss">
                    <a href="https://www.microsoft.com/en-us/research/publication/domain-adaptive-text-style-transfer/" 
                  style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                  Domain Adaptive Text Style Transfer ></a>
                  </div>
                  <div class="sec_sub_title_s">Dianqi Li, Yizhe Zhang, Zhe Gan, Yu Cheng, Chris Brockett, Ming-Ting Sun, Bill Dolan</div>
                  <div class="sec_sub_title_s"><a style="font-weight: bold;">EMNLP</a> | May 2019</div>
                  <div class="sec_sub_title_a">
                    <a href="https://arxiv.org/abs/1908.09395" 
                  style=" color:#3f44b6;" rel="alternate bookmark" target="_blank">
                  View Publication</a>
                  </div>
                </div>
                <!--publication section-->
                   
              </div>
          </div>
          <!--Accordion item-->
      
          </div>
      
      </div>  

    </div>
    </section>

    <section class="scrollspy-section" id="Videos">
      <div class="section_2" >
        <div class="title">Videos
            <div class="line"></div>
        </div>
        <div class="grids">
          <div class="video_list">
            <img src="img/kdBEYwhG6mc-480x280.jpg" alt="" class="list_img">
            <div class="video_padding">
              <div class="sub-title">
                <a href="https://www.youtube.com/watch?v=kdBEYwhG6mc" 
                style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                [REFAI Seminar 06/08/21] Transformer efficiency: From model compression to training acceleration ></a>
              </div>
              <div class="cont overflow">
                July 24, 2022
                <br>Speakers: Yu Cheng
              </div>
            </div>
          </div>
          <div class="video_list">
            <img src="img/8pNtrsFe4tk-480x280.jpg" alt="" class="list_img">
            <div class="video_padding">
              <div class="sub-title">
                <a href="https://youtu.be/8pNtrsFe4tk" 
                style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                [CVPR 2020 Tutorial] Talk #4 Text-to-Image Generation by Yu Cheng ></a>
              </div>
              <div class="cont overflow">
                July 21, 2022
                <br>Speakers: Yu Cheng
              </div>
            </div>
          </div>
          <div class="video_list">
            <img src="img/8m3JTG70yWE-480x280.jpg" alt="" class="list_img">
            <div class="video_padding">
              <div class="sub-title">
                <a href="https://youtu.be/8m3JTG70yWE" 
                style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
                Research talk: Transformer efficiency: From model compression to training acceleration ></a>
              </div>
              <div class="cont overflow">
                October 19, 2021
                <br>Speakers: Yu Cheng
                <br>Affiliation: Microsoft Research Redmond
              </div>
            </div>
          </div>

        </div>


    </div>
    </section>
    <section class="scrollspy-section" id="News & features">
      <div class="section_2" >
        <div class="title">News & features
            <div class="line"></div>
        </div>
        <div class="news_card" style="padding-top:30px;">
          <div class="sec_sub_title">AWARDS | META MODULE NETWORK FOR COMPOSITIONAL VISUAL REASONING</div>
          <div class="sub-title_s">
            <a href="https://wacv2021.thecvf.com/home" 
          style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
          Best Student Paper Honorable Mention, WACV 2021 ></a>
          </div>
          <div class="cont overflow">
            January 5, 2021
          </div>          
        </div>
        <div class="news_card">
          <div class="sec_sub_title">AWARDS | VQA CHALLENGE 2020, 3RD PLACE</div>
          <div class="sub-title_s">
            <a href="https://visualqa.org/roe.html" 
          style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
          3rd Place, VQA Challenge 2020 ></a>
          </div>
          <div class="cont overflow">
            May 15, 2020
          </div>          
        </div>
        <div class="news_card">
          <div class="sec_sub_title">IN THE NEWS | NO. 1 ON GLUE LEADERBOARD</div>
          <div class="sub-title_s">
            <a href="https://drive.google.com/file/d/1PiCZVlmDx1B6vxK5JkAVbYfnC5Xssw7Q/view" 
          style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
          Achieved No. 1 on GLUE Leaderboard ></a>
          </div>
          <div class="cont overflow">
            September 27, 2019
          </div>          
        </div>
        <div class="news_card">
          <div class="sec_sub_title">AWARDS | VISUAL DIALOG CHALLENGE 2019, RUNNER UP</div>
          <div class="sub-title_s">
            <a href="https://visualdialog.org/challenge/2019" 
          style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
          2nd Place, 2019 Visual Dialog Challenge ></a>
          </div>
          <div class="cont overflow">
            June 21, 2019
          </div>          
        </div>
        <div class="news_card" style="border-bottom:none">
          <div class="sec_sub_title">AWARDS | VISUAL DIALOG CHALLENGE 2019, 3RD PLACE</div>
          <div class="sub-title_s">
            <a href="https://visualdialog.org/challenge/2018" 
          style="text-decoration: none; color:#3f44b6;" rel="alternate bookmark" target="_blank">
          3rd Place, 2018 Visual Dialog Challenge ></a>
          </div>
          <div class="cont overflow">
            July 21, 2018
          </div>          
        </div>

      </div>
    </section>

    <div class="gray">
      <div class="section_2" >
        <div class="title">Contact
            <div class="line"></div>
        </div>
        <div class="sec_sub_title" style="margin-top: 60px;">Contact infor</div>
        <div class="sec_sub_title">Contact infor</div>
        <div class="sec_sub_title" style="margin-bottom: 60px;">Contact infor</div>
       </div>

    </div>
    
    <div class="footer">
      <div class="cont_footer">© 2023 All rights reserved</div>

    </div>
    
    <script src="dist/js/mn-accordion.js"></script>
    <script>
        (function () {

            var accordion_2 = new Accordion(document.getElementById("accordion-2"), {
                multiple: true,
                defaultOpenedIndexes: [0]
            });
        })();
    </script>
    <script src="dist/js/scrollspy.min.js"></script>
  </body>
</html>
